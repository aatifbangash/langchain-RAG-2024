{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "SECRET_KEY = config('OPENAI_API_KEY')\n",
    "chat = ChatOpenAI(openai_api_key=SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(content=\"You're a helpful assistant\"),\n",
    "#     HumanMessage(content=\"What is Laravel?\"),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Laravel is a popular open-source PHP framework used for building web applications. It provides a clean and elegant syntax while also offering a wide range of features that help developers quickly and efficiently create robust web applications. Some key features of Laravel include a powerful ORM (Object-Relational Mapping) system, built-in authentication and authorization, routing, caching, and more. Laravel follows the MVC (Model-View-Controller) architectural pattern, making it easy to organize code and separate concerns. It also has a vibrant community and extensive documentation, making it a popular choice for many web developers.')]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(response.content)\n",
    "# chat.batch([messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.codenterprise.com\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1244, which is longer than the specified 250\n",
      "Created a chunk of size 722, which is longer than the specified 250\n",
      "Created a chunk of size 763, which is longer than the specified 250\n",
      "Created a chunk of size 315, which is longer than the specified 250\n",
      "Created a chunk of size 326, which is longer than the specified 250\n",
      "Created a chunk of size 503, which is longer than the specified 250\n",
      "Created a chunk of size 278, which is longer than the specified 250\n",
      "Created a chunk of size 278, which is longer than the specified 250\n",
      "Created a chunk of size 261, which is longer than the specified 250\n",
      "Created a chunk of size 502, which is longer than the specified 250\n",
      "Created a chunk of size 501, which is longer than the specified 250\n",
      "Created a chunk of size 307, which is longer than the specified 250\n",
      "Created a chunk of size 361, which is longer than the specified 250\n",
      "Created a chunk of size 297, which is longer than the specified 250\n",
      "Created a chunk of size 297, which is longer than the specified 250\n",
      "Created a chunk of size 320, which is longer than the specified 250\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "documents  = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "\n",
    "# document_chain = create_stuff_documents_chain(chat, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "retriever_chain = create_history_aware_retriever(chat, retriever, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The CTO at Codenterprise is [Name].'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    # HumanMessage(content=\"Who is Atif ali?\"), \n",
    "    # AIMessage(content=\"Yes!\")\n",
    "]\n",
    "\n",
    "response = retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history, \n",
    "    \"input\": \"List me the names of Software enginners?\"\n",
    "    })\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(chat, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)\n",
    "\n",
    "chat_history = [HumanMessage(content=\"List me the names of Software enginners?\"), AIMessage(content=\"Yes!\")]\n",
    "response = retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me the list of all\"\n",
    "})\n",
    "\n",
    "# from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# chat_history = [HumanMessage(content=\"Who is Atif ali?\"), AIMessage(content=\"Yes!\")]\n",
    "# response = retriever_chain.invoke({\n",
    "#     \"chat_history\": chat_history,\n",
    "#     \"input\": \"Who is Atif ali?\"\n",
    "# })\n",
    "\n",
    "pprint(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
